# POI Survival Analysis Project - Directory Structure

## Overview
This project analyzes Point of Interest (POI) survival in Jakarta using spatial features and survival analysis models.

---

## Current Directory Structure

```
POI/
â”‚
â”œâ”€â”€ ğŸ“„ Main Scripts & Notebooks (Root)
â”‚   â”œâ”€â”€ kaggle_feature_extraction_with_checkpoints.py    â­ MAIN FEATURE EXTRACTION SCRIPT
â”‚   â”œâ”€â”€ kaggle_feature_extraction_complete.ipynb         Main feature extraction notebook
â”‚   â”œâ”€â”€ kaggle_survival_training_advanced.ipynb          Model training notebook
â”‚   â”œâ”€â”€ kaggle_feature_importance_analysis.ipynb         Feature analysis notebook
â”‚   â”œâ”€â”€ requirements.txt                                  Python dependencies
â”‚   â””â”€â”€ cleanup_and_organize.py                          Directory cleanup utility
â”‚
â”œâ”€â”€ ğŸ“ src/                                              Source Code Modules
â”‚   â”œâ”€â”€ data/                                             Data collection & loading
â”‚   â”‚   â”œâ”€â”€ collect_bps.py
â”‚   â”‚   â”œâ”€â”€ collect_foursquare.py
â”‚   â”‚   â”œâ”€â”€ collect_osm.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â””â”€â”€ survival_labeler.py
â”‚   â”œâ”€â”€ features/                                         Feature engineering
â”‚   â”‚   â”œâ”€â”€ feature_engineer.py
â”‚   â”‚   â””â”€â”€ spatial_features.py
â”‚   â”œâ”€â”€ models/                                           Model training
â”‚   â”‚   â”œâ”€â”€ survival_trainer.py
â”‚   â”‚   â””â”€â”€ train_model.py
â”‚   â””â”€â”€ utils/                                            Utilities
â”‚       â”œâ”€â”€ config_loader.py
â”‚       â””â”€â”€ experiment_tracker.py
â”‚
â”œâ”€â”€ ğŸ“ data/processed/                                   Raw Input Data
â”‚   â”œâ”€â”€ foursquare/
â”‚   â”‚   â””â”€â”€ jakarta_pois_foursquare_iceberg.csv
â”‚   â”œâ”€â”€ osm/
â”‚   â”‚   â””â”€â”€ jakarta_pois_osm.csv
â”‚   â”œâ”€â”€ buildings/
â”‚   â”‚   â””â”€â”€ jakarta_buildings_osm.csv
â”‚   â””â”€â”€ bps/
â”‚       â”œâ”€â”€ jakarta_regencies.csv
â”‚       â””â”€â”€ provinces.csv
â”‚
â”œâ”€â”€ ğŸ“ outputs/                                          Generated Outputs
â”‚   â”œâ”€â”€ kaggle_clean_data/
â”‚   â”‚   â””â”€â”€ jakarta_clean_categorized.csv                â­ MAIN CLEANED DATASET (27MB)
â”‚   â”œâ”€â”€ kaggle_raw_data/
â”‚   â”‚   â””â”€â”€ jakarta_selatan_raw.csv
â”‚   â”œâ”€â”€ features/                                         (Will contain feature outputs)
â”‚   â””â”€â”€ archive/                                          Old/intermediate outputs
â”‚       â”œâ”€â”€ jakarta_restaurant_phase1_demographics.csv
â”‚       â”œâ”€â”€ jakarta_restaurant_phase1_2_5_combined.csv
â”‚       â”œâ”€â”€ coffee_shops_with_features.csv
â”‚       â”œâ”€â”€ feature_importance.csv
â”‚       â”œâ”€â”€ survival_analysis/
â”‚       â”œâ”€â”€ survival_analysis_jaksel/
â”‚       â””â”€â”€ survival_analysis_jaksel_fast/
â”‚
â”œâ”€â”€ ğŸ“ archive/                                          Archived Files
â”‚   â”œâ”€â”€ notebooks/                                        Old/experimental notebooks (11 files)
â”‚   â”‚   â”œâ”€â”€ kaggle_phase1_demographics.ipynb
â”‚   â”‚   â”œâ”€â”€ kaggle_phase2_competition.ipynb
â”‚   â”‚   â”œâ”€â”€ kaggle_phase3_accessibility.ipynb
â”‚   â”‚   â”œâ”€â”€ kaggle_phase4_indonesia_specific.ipynb
â”‚   â”‚   â”œâ”€â”€ kaggle_phases_all_in_one.ipynb
â”‚   â”‚   â””â”€â”€ ... (6 more)
â”‚   â””â”€â”€ scripts/                                          Old data collection scripts (18 files)
â”‚       â”œâ”€â”€ collect_boundaries.py
â”‚       â”œâ”€â”€ collect_buildings.py
â”‚       â”œâ”€â”€ create_clean_categorized_dataset.py
â”‚       â””â”€â”€ ... (15 more)
â”‚
â””â”€â”€ ğŸ“ notebooks/                                        Original Exploratory Notebooks
    â”œâ”€â”€ 01_data_collection.ipynb
    â”œâ”€â”€ 01_exploratory_data_analysis.ipynb
    â””â”€â”€ 04_model_training.ipynb
```

---

## Key Files

### ğŸ¯ Production Files (What You Need)

1. **kaggle_feature_extraction_with_checkpoints.py** â­
   - Complete feature extraction pipeline
   - Saves checkpoints after each section
   - Works on both Kaggle and local
   - Generates 128+ features

2. **jakarta_clean_categorized.csv** â­
   - Main input dataset (158,377 POIs)
   - Located in: `outputs/kaggle_clean_data/`
   - Contains: 77,918 restaurants

3. **kaggle_survival_training_advanced.ipynb**
   - Model training notebook
   - Uses extracted features for survival prediction

4. **kaggle_feature_importance_analysis.ipynb**
   - Analyzes which features are most important
   - Feature importance visualization

---

## Workflow

### Step 1: Feature Extraction
```bash
python kaggle_feature_extraction_with_checkpoints.py
```

**Output:**
- `outputs/features/jakarta_restaurant_features_complete.csv` (Final dataset with 128+ features)
- `outputs/features/checkpoint_*.csv` (9 checkpoint files)
- `outputs/features/feature_list_complete.txt` (Feature documentation)

### Step 2: Model Training
Open and run: `kaggle_survival_training_advanced.ipynb`

### Step 3: Analysis
Open and run: `kaggle_feature_importance_analysis.ipynb`

---

## Feature Groups (128+ Features)

Generated by the feature extraction script:

| Group | Count | Examples |
|-------|-------|----------|
| Shannon Entropy | 3 | `entropy_500m`, `entropy_1000m`, `entropy_2000m` |
| POI Counts | 48 | `competitors_count_500m`, `mall_count_1000m` |
| POI Densities | 49 | `competitors_density_500m`, `office_density_1000m` |
| Distances | 8 | `nearest_competitor_m`, `dist_city_center_km` |
| Competition | 3 | `avg_competitor_dist_2km`, `cannibalization_risk_500m` |
| Demographics | 3 | `income_district_m`, `density_district`, `working_age_district` |
| Accessibility | 3 | `dist_city_center_km`, `transport_density_1km`, `urban_centrality` |
| Interactions | 6 | `income_pop_interaction`, `office_transport`, `demand_supply_ratio` |
| Indonesia-Specific | 36 | `mosque_count_500m`, `pasar_proximity_score`, `friday_prayer_impact` |
| Temporal | 5 | `ramadan_evening_multiplier`, `gajian_multiplier` |

**Total: 128 features**

---

## Cleanup Summary

### Files Archived
- âœ… 11 old/experimental notebooks â†’ `archive/notebooks/`
- âœ… 18 old data collection scripts â†’ `archive/scripts/`
- âœ… 7 intermediate output files â†’ `outputs/archive/`

### Files Kept
- âœ… 4 essential notebooks (feature extraction, training, analysis)
- âœ… 1 main production script (with checkpoints)
- âœ… Source code modules (`src/`)
- âœ… Main dataset (27MB)
- âœ… Requirements.txt

---

## Next Steps

1. **Run Feature Extraction:**
   ```bash
   python kaggle_feature_extraction_with_checkpoints.py
   ```
   Expected runtime: ~60-90 minutes
   Output: `outputs/features/jakarta_restaurant_features_complete.csv`

2. **Upload to Kaggle:**
   - Upload the generated feature CSV to Kaggle dataset
   - Use in training notebook

3. **Train Models:**
   - Open `kaggle_survival_training_advanced.ipynb`
   - Run all cells to train survival models

4. **Analyze Results:**
   - Open `kaggle_feature_importance_analysis.ipynb`
   - Identify top features

---

## Data Flow

```
data/processed/             â†’    outputs/kaggle_clean_data/    â†’    outputs/features/
(Raw POI data)                   (Cleaned & categorized)            (Extracted features)
                                 jakarta_clean_categorized.csv      jakarta_restaurant_features_complete.csv
                                 158,377 POIs                       72,082 mature restaurants
                                                                    128+ features each
```

---

## Requirements

Install dependencies:
```bash
pip install -r requirements.txt
```

Main packages:
- pandas
- geopandas
- numpy
- scikit-survival
- shapely
- tqdm

---

## Notes

- All archived files are safe to delete if needed (kept for reference)
- Main dataset is in `outputs/kaggle_clean_data/`
- Feature extraction saves checkpoints automatically
- Both Kaggle and local environments supported

---

**Last Updated:** 2025-11-19
**Project:** POI Survival Analysis - Jakarta Restaurants
