{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant Survival - GBS with Proven Features\n",
    "\n",
    "**üéØ Goal**: Reproduce C-index 0.76 using Gradient Boosting Survival\n",
    "\n",
    "**Strategy**: Use proven 8 features from thematic experiment\n",
    "\n",
    "**Dataset**: 72,082 mature restaurants (5.5% failure)\n",
    "\n",
    "**Model**: Gradient Boosting Survival Analysis (faster than RSF)\n",
    "\n",
    "**Expected Time**: 5-10 minutes (CPU only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q scikit-survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis, RandomSurvivalForest\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.util import Surv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"‚úÖ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_PATH = Path('/kaggle/input/jakarta-restaurant-features-complete')\n",
    "OUTPUT_PATH = Path('/kaggle/working')\n",
    "OUTPUT_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Data: {DATA_PATH}\")\n",
    "print(f\"üìÅ Output: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(DATA_PATH / 'jakarta_restaurant_features_complete.csv')\n",
    "\n",
    "print(f\"‚úÖ Loaded: {len(df):,} restaurants\")\n",
    "print(f\"   Failures: {(df['event_observed'] == 1).sum():,} ({(df['event_observed'] == 1).mean():.1%})\")\n",
    "print(f\"   Successes: {(df['event_observed'] == 0).sum():,} ({(df['event_observed'] == 0).mean():.1%})\")\n",
    "print(f\"\\n‚ö†Ô∏è  Imbalance ratio: {(df['event_observed'] == 0).sum() / (df['event_observed'] == 1).sum():.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Proven Features\n",
    "\n",
    "Based on Thematic Experiment (C-index 0.7599):\n",
    "- 8 features with 5km buffer\n",
    "- Focus on competition, demographics, accessibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proven 8 features from thematic experiment\n",
    "PROVEN_FEATURES_8 = [\n",
    "    'competitors_count_5000m',    # Competition in 5km (was competitors_5000m)\n",
    "    'nearest_competitor_m',        # Distance to nearest competitor\n",
    "    'density_district',            # Population density\n",
    "    'income_district_m',           # District income\n",
    "    'working_age_district',        # Working age population\n",
    "    'transport_count_5000m',       # Transport access in 5km\n",
    "    'dist_city_center_km',         # Distance to city center\n",
    "    'pasar_count_5000m'            # Traditional markets in 5km\n",
    "]\n",
    "\n",
    "# Alternative: Top features from Feature Importance Analysis\n",
    "TOP_FEATURES_10 = [\n",
    "    'pasar_count_1000m',           # 89.5% importance - DOMINANT!\n",
    "    'transport_density_1km',       # 67% importance\n",
    "    'transport_count_1000m',       # 56% importance\n",
    "    'working_age_district',        # 48% importance\n",
    "    'density_district',            # 45% importance\n",
    "    'nearest_competitor_m',        # Competition factor\n",
    "    'dist_city_center_km',         # Accessibility\n",
    "    'income_district_m',           # Income level\n",
    "    'competitors_count_5000m',     # Competition count\n",
    "    'office_transport'             # Interaction feature\n",
    "]\n",
    "\n",
    "print(\"üìã Feature Sets Defined:\")\n",
    "print(f\"   Set 1 (Proven 8): {len(PROVEN_FEATURES_8)} features\")\n",
    "print(f\"   Set 2 (Top 10): {len(TOP_FEATURES_10)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which features exist\n",
    "all_features = list(df.columns)\n",
    "\n",
    "print(\"\\nüîç Checking Proven 8 Features:\")\n",
    "for f in PROVEN_FEATURES_8:\n",
    "    status = \"‚úì\" if f in all_features else \"‚úó\"\n",
    "    print(f\"   {status} {f}\")\n",
    "\n",
    "print(\"\\nüîç Checking Top 10 Features:\")\n",
    "for f in TOP_FEATURES_10:\n",
    "    status = \"‚úì\" if f in all_features else \"‚úó\"\n",
    "    print(f\"   {status} {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter valid features only\n",
    "proven_8_valid = [f for f in PROVEN_FEATURES_8 if f in all_features]\n",
    "top_10_valid = [f for f in TOP_FEATURES_10 if f in all_features]\n",
    "\n",
    "print(f\"‚úÖ Valid features:\")\n",
    "print(f\"   Proven 8: {len(proven_8_valid)}/{len(PROVEN_FEATURES_8)}\")\n",
    "print(f\"   Top 10: {len(top_10_valid)}/{len(TOP_FEATURES_10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Survival Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare and train model\n",
    "def train_survival_model(df, feature_list, model_type='GBS', name=\"\"):\n",
    "    \"\"\"\n",
    "    Train survival model and return results\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with features and survival data\n",
    "        feature_list: List of feature names to use\n",
    "        model_type: 'GBS' or 'RSF'\n",
    "        name: Name for this run\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üî• TRAINING: {name}\")\n",
    "    print(f\"   Model: {model_type}\")\n",
    "    print(f\"   Features: {len(feature_list)}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Fill missing values\n",
    "    df_model = df.copy()\n",
    "    df_model[feature_list] = df_model[feature_list].fillna(df_model[feature_list].median())\n",
    "    \n",
    "    # Create survival array\n",
    "    y = Surv.from_arrays(\n",
    "        event=df_model['event_observed'].astype(bool),\n",
    "        time=df_model['survival_days']\n",
    "    )\n",
    "    \n",
    "    X = df_model[feature_list].values\n",
    "    \n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=df_model['event_observed']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Data split: Train {len(X_train):,} | Test {len(X_test):,}\")\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train model\n",
    "    start = time.time()\n",
    "    \n",
    "    if model_type == 'GBS':\n",
    "        model = GradientBoostingSurvivalAnalysis(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=5,\n",
    "            min_samples_split=10,\n",
    "            subsample=0.8,\n",
    "            random_state=42,\n",
    "            verbose=0\n",
    "        )\n",
    "    else:  # RSF\n",
    "        model = RandomSurvivalForest(\n",
    "            n_estimators=100,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=5,\n",
    "            max_features='sqrt',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "    \n",
    "    print(f\"\\n‚è≥ Training {model_type}...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    # Predict\n",
    "    pred_train = model.predict(X_train_scaled)\n",
    "    pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    # C-index\n",
    "    c_train = concordance_index_censored(y_train['event'], y_train['time'], pred_train)[0]\n",
    "    c_test = concordance_index_censored(y_test['event'], y_test['time'], pred_test)[0]\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training complete in {elapsed:.1f}s\")\n",
    "    print(f\"\\nüìä RESULTS:\")\n",
    "    print(f\"   Train C-index: {c_train:.4f}\")\n",
    "    print(f\"   Test C-index:  {c_test:.4f}\")\n",
    "    print(f\"   Overfitting:   {c_train - c_test:.4f}\")\n",
    "    \n",
    "    # Feature importance (if available)\n",
    "    importance = None\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importance = model.feature_importances_\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_list,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        importance_df['importance_pct'] = importance_df['importance'] / importance_df['importance'].sum() * 100\n",
    "        \n",
    "        print(f\"\\nüìä Top 5 Features:\")\n",
    "        for i, row in importance_df.head(5).iterrows():\n",
    "            print(f\"   {row['feature']:30s} {row['importance_pct']:6.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'name': name,\n",
    "        'model_type': model_type,\n",
    "        'n_features': len(feature_list),\n",
    "        'features': feature_list,\n",
    "        'c_train': c_train,\n",
    "        'c_test': c_test,\n",
    "        'time_s': elapsed,\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'importance': importance_df if importance is not None else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Proven 8 Features with GBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_proven_gbs = train_survival_model(\n",
    "    df, \n",
    "    proven_8_valid, \n",
    "    model_type='GBS',\n",
    "    name=\"Proven 8 Features (GBS)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Proven 8 Features with RSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_proven_rsf = train_survival_model(\n",
    "    df, \n",
    "    proven_8_valid, \n",
    "    model_type='RSF',\n",
    "    name=\"Proven 8 Features (RSF)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Top 10 Features with GBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_top10_gbs = train_survival_model(\n",
    "    df, \n",
    "    top_10_valid, \n",
    "    model_type='GBS',\n",
    "    name=\"Top 10 Features (GBS)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Top 10 Features with RSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_top10_rsf = train_survival_model(\n",
    "    df, \n",
    "    top_10_valid, \n",
    "    model_type='RSF',\n",
    "    name=\"Top 10 Features (RSF)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results\n",
    "results = [\n",
    "    result_proven_gbs,\n",
    "    result_proven_rsf,\n",
    "    result_top10_gbs,\n",
    "    result_top10_rsf\n",
    "]\n",
    "\n",
    "df_results = pd.DataFrame([{\n",
    "    'name': r['name'],\n",
    "    'model': r['model_type'],\n",
    "    'features': r['n_features'],\n",
    "    'c_train': r['c_train'],\n",
    "    'c_test': r['c_test'],\n",
    "    'overfitting': r['c_train'] - r['c_test'],\n",
    "    'time_s': r['time_s']\n",
    "} for r in results])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä FINAL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "df_results.to_csv(OUTPUT_PATH / 'comparison_results.csv', index=False)\n",
    "\n",
    "# Best model\n",
    "best_idx = df_results['c_test'].idxmax()\n",
    "best = df_results.iloc[best_idx]\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL:\")\n",
    "print(f\"   Name: {best['name']}\")\n",
    "print(f\"   C-index: {best['c_test']:.4f}\")\n",
    "print(f\"   Time: {best['time_s']:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 1. C-index comparison\n",
    "ax1 = axes[0]\n",
    "x = range(len(df_results))\n",
    "ax1.barh(x, df_results['c_test'], alpha=0.7)\n",
    "ax1.set_yticks(x)\n",
    "ax1.set_yticklabels(df_results['name'], fontsize=9)\n",
    "ax1.set_xlabel('Test C-index')\n",
    "ax1.set_title('Model Performance Comparison')\n",
    "ax1.axvline(x=0.76, color='g', linestyle='--', alpha=0.5, label='Target 0.76')\n",
    "ax1.legend()\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# 2. Feature importance (best model)\n",
    "ax2 = axes[1]\n",
    "best_result = results[best_idx]\n",
    "if best_result['importance'] is not None:\n",
    "    top_imp = best_result['importance'].head(10)\n",
    "    ax2.barh(range(len(top_imp)), top_imp['importance_pct'])\n",
    "    ax2.set_yticks(range(len(top_imp)))\n",
    "    ax2.set_yticklabels(top_imp['feature'], fontsize=9)\n",
    "    ax2.set_xlabel('Importance (%)')\n",
    "    ax2.set_title(f'Top 10 Features ({best[\"name\"]})')\n",
    "    ax2.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PATH / 'comparison_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model configuration\n",
    "best_result = results[best_idx]\n",
    "\n",
    "config = {\n",
    "    'name': best_result['name'],\n",
    "    'model_type': best_result['model_type'],\n",
    "    'n_features': best_result['n_features'],\n",
    "    'features': best_result['features'],\n",
    "    'c_train': float(best_result['c_train']),\n",
    "    'c_test': float(best_result['c_test']),\n",
    "    'time_s': float(best_result['time_s']),\n",
    "    'dataset': {\n",
    "        'total': len(df),\n",
    "        'failures': int((df['event_observed'] == 1).sum()),\n",
    "        'failure_rate': float((df['event_observed'] == 1).mean())\n",
    "    },\n",
    "    'target_c_index': 0.76,\n",
    "    'achieved': best_result['c_test'] >= 0.70\n",
    "}\n",
    "\n",
    "# Save feature importance\n",
    "if best_result['importance'] is not None:\n",
    "    best_result['importance'].to_csv(OUTPUT_PATH / 'best_model_feature_importance.csv', index=False)\n",
    "    config['top_5_features'] = best_result['importance'].head(5)['feature'].tolist()\n",
    "\n",
    "with open(OUTPUT_PATH / 'best_model_config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Best model configuration saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìù FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset:\")\n",
    "print(f\"   Total: {len(df):,} restaurants\")\n",
    "print(f\"   Failures: {(df['event_observed'] == 1).sum():,} ({(df['event_observed'] == 1).mean():.1%})\")\n",
    "print(f\"   Imbalance: {(df['event_observed'] == 0).sum() / (df['event_observed'] == 1).sum():.1f}:1\")\n",
    "\n",
    "print(f\"\\n‚úÖ Experiments Run: {len(results)}\")\n",
    "print(f\"   1. Proven 8 + GBS: {result_proven_gbs['c_test']:.4f}\")\n",
    "print(f\"   2. Proven 8 + RSF: {result_proven_rsf['c_test']:.4f}\")\n",
    "print(f\"   3. Top 10 + GBS: {result_top10_gbs['c_test']:.4f}\")\n",
    "print(f\"   4. Top 10 + RSF: {result_top10_rsf['c_test']:.4f}\")\n",
    "\n",
    "print(f\"\\nüèÜ Best Result:\")\n",
    "print(f\"   Model: {best['name']}\")\n",
    "print(f\"   C-index: {best['c_test']:.4f}\")\n",
    "print(f\"   Target: 0.7600\")\n",
    "print(f\"   Gap: {0.76 - best['c_test']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "if best['c_test'] >= 0.76:\n",
    "    print(\"‚úÖ SUCCESS: C-index ‚â• 0.76 (Target achieved!)\")\n",
    "elif best['c_test'] >= 0.70:\n",
    "    print(\"‚úÖ GOOD: C-index ‚â• 0.70 (Close to target!)\")\n",
    "elif best['c_test'] >= 0.60:\n",
    "    print(\"‚ö†Ô∏è  MODERATE: C-index 0.60-0.70 (Needs improvement)\")\n",
    "else:\n",
    "    print(\"‚ùå POOR: C-index < 0.60 (Significant improvement needed)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüéâ TRAINING COMPLETE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
